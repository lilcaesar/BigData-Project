{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usare object_detection vecchio (in locale)\n",
    "!git clone https://github.com/tensorflow/models.git\n",
    "!apt-get -qq install libprotobuf-java protobuf-compiler\n",
    "!protoc ./models/research/object_detection/protos/string_int_label_map.proto --python_out=.\n",
    "!cp -R models/research/object_detection/ object_detection/\n",
    "!rm -rf models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install numpy\n",
    "!pip3 install tensorflow-gpu\n",
    "!pip3 install opencv-contrib-python\n",
    "!pip3 install matplotlib\n",
    "!pip3 install Pillow\n",
    "!pip3 install scipy\n",
    "!pip3 install opencv-python\n",
    "!apt update && apt install -y libsm6 libxext6\n",
    "!apt-get install -y libxrender-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import cv2\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.stats import itemfreq\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir training\n",
    "!mkdir annotations\n",
    "!mkdir pre-trained-model\n",
    "!mkdir images\n",
    "\n",
    "!mkdir images/test\n",
    "!mkdir images/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = os.path.join('annotations', 'label_map.pbtxt')\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "opener = urllib.request.URLopener()\n",
    "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "for file in tar_file.getmembers():\n",
    "  file_name = os.path.basename(file.name)\n",
    "  if 'frozen_inference_graph.pb' in file_name:\n",
    "    tar_file.extract(file, os.getcwd())\n",
    "    \n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')\n",
    "    \n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/tensorflow/models.git\n",
    "!apt-get -qq install libprotobuf-java protobuf-compiler\n",
    "!protoc ./models/research/object_detection/protos/string_int_label_map.proto --python_out=.\n",
    "!cp -R models/research/slim/nets nets/\n",
    "!rm -rf models\n",
    "\n",
    "!git clone https://github.com/tensorflow/models.git\n",
    "!apt-get -qq install libprotobuf-java protobuf-compiler\n",
    "!protoc ./models/research/object_detection/protos/string_int_label_map.proto --python_out=.\n",
    "!cp -R models/research/slim/deployment deployment/\n",
    "!rm -rf models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install unrar\n",
    "#!unrar x object_detection.rar\n",
    "!protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()\n",
    "device_lib.list_local_devices()\n",
    "# !pip install --no-index -f https://dist.plone.org/thirdparty/ -U PIL\n",
    "# !pip install Pillow\n",
    "#!apt install -y nvidia-387\n",
    "#!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia -smi\n",
    "# !lspci | grep -i nvidia\n",
    "#!apt-cache search nvidia | grep -E \"nvidia\\-[0-9]{3}\"\n",
    "#!dpkg -l | grep -E \"nvidia-[0-9]{3}\"\n",
    "# !apt-cache policy nvidia-410\n",
    "\n",
    "#! add-apt-repository -y ppa:graphics-drivers/ppa                          \n",
    "#!apt install -y nvidia-410  \n",
    "#!dpkg --configure -a\n",
    "!apt-get -f install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "    !CUDA_VISIBLE_DEVICES=1 python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_coco.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/ssd_mobilenet_v2_coco.config --trained_checkpoint_prefix training/model.ckpt-200000 --output_directory trained-inference-graphs/output_inference_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): cython in /usr/local/lib/python3.5/dist-packages\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31mInvalid requirement: 'pycocotools^'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/python-wheels/packaging-16.6-py2.py3-none-any.whl/packaging/requirements.py\", line 90, in __init__\n",
      "    req = REQUIREMENT.parseString(requirement_string)\n",
      "  File \"/usr/share/python-wheels/pyparsing-2.0.3-py2.py3-none-any.whl/pyparsing.py\", line 1125, in parseString\n",
      "    raise exc\n",
      "  File \"/usr/share/python-wheels/pyparsing-2.0.3-py2.py3-none-any.whl/pyparsing.py\", line 1115, in parseString\n",
      "    loc, tokens = self._parse( instring, 0 )\n",
      "  File \"/usr/share/python-wheels/pyparsing-2.0.3-py2.py3-none-any.whl/pyparsing.py\", line 989, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"/usr/share/python-wheels/pyparsing-2.0.3-py2.py3-none-any.whl/pyparsing.py\", line 2378, in parseImpl\n",
      "    loc, exprtokens = e._parse( instring, loc, doActions )\n",
      "  File \"/usr/share/python-wheels/pyparsing-2.0.3-py2.py3-none-any.whl/pyparsing.py\", line 993, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"/usr/share/python-wheels/pyparsing-2.0.3-py2.py3-none-any.whl/pyparsing.py\", line 2183, in parseImpl\n",
      "    raise ParseException(instring, loc, self.errmsg, self)\n",
      "pyparsing.ParseException: Expected stringEnd (at char 11), (line:1, col:12)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/pip/req/req_install.py\", line 78, in __init__\n",
      "    req = Requirement(req)\n",
      "  File \"/usr/share/python-wheels/packaging-16.6-py2.py3-none-any.whl/packaging/requirements.py\", line 94, in __init__\n",
      "    requirement_string[e.loc:e.loc + 8]))\n",
      "pip._vendor.packaging.requirements.InvalidRequirement: Invalid requirement, parse error at \"'^'\"\n",
      "\u001b[0m\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"eval.py\", line 52, in <module>\n",
      "    from object_detection.legacy import evaluator\n",
      "  File \"/home/object_detection/legacy/evaluator.py\", line 24, in <module>\n",
      "    from object_detection import eval_util\n",
      "  File \"/home/object_detection/eval_util.py\", line 27, in <module>\n",
      "    from object_detection.metrics import coco_evaluation\n",
      "  File \"/home/object_detection/metrics/coco_evaluation.py\", line 20, in <module>\n",
      "    from object_detection.metrics import coco_tools\n",
      "  File \"/home/object_detection/metrics/coco_tools.py\", line 47, in <module>\n",
      "    from pycocotools import coco\n",
      "ImportError: No module named pycocotools\n"
     ]
    }
   ],
   "source": [
    "# da installare:\n",
    "# !pip3 install cython\n",
    "# !pip3 install \"git+https://github.com/philferriere/cocoapi.git#egg=pycocotools^&subdirectory=PythonAPI\"\n",
    "\n",
    "# !python eval.py --logtostderr \\\n",
    "# --train_dir=training \\\n",
    "# --pipeline_config_path=training/ssd_mobilenet_v2.config \\\n",
    "# --checkpoint_dir=training --eval_dir=evaluation \\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
